{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cpsc 585 project 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09VTSkU5PU0t"
      },
      "source": [
        "#Mark Johnston CPSC 585 Project #2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkDyhOWHUJMs"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XC3BWXiVqWV"
      },
      "source": [
        "#Imported code for mnist_mlp.py with modification for tf.keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pigJlunAVzWZ"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SfbRAA8Z0QT"
      },
      "source": [
        "#Get EMNIST letters data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s68gSerq2pkA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d511022d-1b85-43bd-a29d-c4a91cd7a940"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bodAsjpdbDW"
      },
      "source": [
        "#code from stackoverflow link\n",
        "from scipy import io as sio\n",
        "mat = sio.loadmat('/content/drive/My Drive/Colab Notebooks/emnist-letters.mat')\n",
        "data = mat['dataset']\n",
        "\n",
        "X_train = data['train'][0,0]['images'][0,0]\n",
        "y_train = data['train'][0,0]['labels'][0,0]\n",
        "X_test = data['test'][0,0]['images'][0,0]\n",
        "y_test = data['test'][0,0]['labels'][0,0]\n",
        "\n",
        "val_start = X_train.shape[0] - X_test.shape[0]\n",
        "X_val = X_train[val_start:X_train.shape[0],:]\n",
        "y_val = y_train[val_start:X_train.shape[0]]\n",
        "X_train = X_train[0:val_start,:]\n",
        "y_train = y_train[0:val_start]\n",
        "\n",
        "#change the vectors to have numbers from 0-25 for the to_categorical function\n",
        "y_train = y_train - 1\n",
        "y_val = y_val - 1\n",
        "y_test = y_test - 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmgsWLyR62xZ"
      },
      "source": [
        "#Applying mnist_mlp.py to the emnist data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt8-VMNV62IS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "a76307db-b045-41b2-9354-0955f8867e28"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "batch_size = 256\n",
        "num_classes = 26\n",
        "epochs = 10\n",
        "\n",
        "#x_train = x_train.reshape(60000, 784)\n",
        "#x_test = x_test.reshape(10000, 784)\n",
        "X_train = X_train.astype('float32')\n",
        "X_val = X_val.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_val /= 255\n",
        "X_test /= 255\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_val.shape[0], 'validation samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Dense(2048, activation='relu', input_shape=(784,)))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(2048, activation='relu'))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(X_val, y_val))\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "104000 train samples\n",
            "20800 validation samples\n",
            "20800 test samples\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_33 (Dense)             (None, 2048)              1607680   \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 26)                53274     \n",
            "=================================================================\n",
            "Total params: 5,857,306\n",
            "Trainable params: 5,857,306\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "407/407 [==============================] - 102s 250ms/step - loss: 0.6470 - accuracy: 0.7986 - val_loss: 0.3831 - val_accuracy: 0.8767\n",
            "Epoch 2/10\n",
            "407/407 [==============================] - 94s 230ms/step - loss: 0.3258 - accuracy: 0.8928 - val_loss: 0.3242 - val_accuracy: 0.8988\n",
            "Epoch 3/10\n",
            "407/407 [==============================] - 90s 222ms/step - loss: 0.2664 - accuracy: 0.9116 - val_loss: 0.3361 - val_accuracy: 0.8994\n",
            "Epoch 4/10\n",
            "407/407 [==============================] - 90s 220ms/step - loss: 0.2325 - accuracy: 0.9220 - val_loss: 0.3513 - val_accuracy: 0.8999\n",
            "Epoch 5/10\n",
            "407/407 [==============================] - 90s 222ms/step - loss: 0.2164 - accuracy: 0.9275 - val_loss: 0.3337 - val_accuracy: 0.9124\n",
            "Epoch 6/10\n",
            "407/407 [==============================] - 88s 217ms/step - loss: 0.2004 - accuracy: 0.9326 - val_loss: 0.3167 - val_accuracy: 0.9180\n",
            "Epoch 7/10\n",
            "407/407 [==============================] - 88s 217ms/step - loss: 0.1904 - accuracy: 0.9360 - val_loss: 0.3370 - val_accuracy: 0.9130\n",
            "Epoch 8/10\n",
            "407/407 [==============================] - 88s 216ms/step - loss: 0.1835 - accuracy: 0.9387 - val_loss: 0.3801 - val_accuracy: 0.9117\n",
            "Epoch 9/10\n",
            "407/407 [==============================] - 89s 218ms/step - loss: 0.1757 - accuracy: 0.9405 - val_loss: 0.3778 - val_accuracy: 0.9191\n",
            "Epoch 10/10\n",
            "407/407 [==============================] - 88s 217ms/step - loss: 0.1680 - accuracy: 0.9421 - val_loss: 0.3808 - val_accuracy: 0.9190\n",
            "Test loss: 0.37656399607658386\n",
            "Test accuracy: 0.9190384745597839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCOYy5Hs6ip3"
      },
      "source": [
        "#Results\n",
        "\n",
        "Initial trial with no changes:\n",
        ">batch_size = 128\n",
        "\n",
        ">epochs = 20\n",
        "\n",
        ">dropout = .2\n",
        "\n",
        ">Validation Accuracy = 91.3% (0.9129)\n",
        "\n",
        ">Test Accuracy = 91.1% (0.9108173251152039), compared to a 98.3% (0.983299970626831) accuracy for mnist\n",
        "\n",
        "After updating the number of neurons in the hidden layer (no other changes):\n",
        ">Number of neurons = 2048 (Anything much higher than this took way too long to train)\n",
        "\n",
        ">Validation Accuracy = 91.3% (0.9125)\n",
        "\n",
        "Trial and error to find highest value for validation set ended up with:\n",
        "\n",
        ">batch_size = 256\n",
        "\n",
        ">epochs = 10\n",
        "\n",
        ">dropout = .2\n",
        "\n",
        ">Validation accuracy = 91.9% (0.9190)\n",
        "\n",
        "Final test results comparison:\n",
        "\n",
        "> Final test accuracy = 91.9% (0.9190384745597839)\n",
        "\n",
        "> Difference = 91.9% - 91.1% = 0.8% increase\n"
      ]
    }
  ]
}